{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gtmQDB6EjReV"
      },
      "outputs": [],
      "source": [
        "# First import the functions we will need\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahjuiLjgtBcX"
      },
      "outputs": [],
      "source": [
        "# This script requires TensorFlow 2 and Python 3.\n",
        "if tf.__version__.split('.')[0] != '2':\n",
        "    raise Exception((f\"The script is developed and tested for tensorflow 2. \"\n",
        "                     f\"Current version: {tf.__version__}\"))\n",
        "\n",
        "if sys.version_info.major < 3:\n",
        "    raise Exception((f\"The script is developed and tested for Python 3. \"\n",
        "                     f\"Current version: {sys.version_info.major}\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9O5-58WYokl3"
      },
      "source": [
        "# GradientTape\n",
        "\n",
        "The Calculus is managed by a TensorFlow Gradient Tape. You can learn more about the gradient tape at https://www.tensorflow.org/api_docs/python/tf/GradientTape, and we will discuss it later in the course."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JdhgbGE2j02L"
      },
      "outputs": [],
      "source": [
        "# Define our initial guess\n",
        "INITIAL_W = 10.0\n",
        "INITIAL_B = 10.0\n",
        "\n",
        "# Define our loss function\n",
        "def loss(predicted_y, target_y):\n",
        "  return tf.reduce_mean(tf.square(predicted_y - target_y))\n",
        "\n",
        "# Define our training procedure\n",
        "def train(model, inputs, outputs, learning_rate):\n",
        "  with tf.GradientTape() as t:\n",
        "    current_loss = loss(model(inputs), outputs)\n",
        "    # Here is where you differentiate the model values with respect to the loss function\n",
        "    dw, db = t.gradient(current_loss, [model.w, model.b])\n",
        "    # And here is where you update the model values based on the learning rate chosen\n",
        "    model.w.assign_sub(learning_rate * dw)\n",
        "    model.b.assign_sub(learning_rate * db)\n",
        "    return current_loss\n",
        "\n",
        "# Define our simple linear regression model\n",
        "class Model(object):\n",
        "  def __init__(self):\n",
        "    # Initialize the weights\n",
        "    self.w = tf.Variable(INITIAL_W)\n",
        "    self.b = tf.Variable(INITIAL_B)\n",
        "\n",
        "  def __call__(self, x):\n",
        "    return self.w * x + self.b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8HCJcXZtBcj"
      },
      "source": [
        "### Train our model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8akmDCoAjgak"
      },
      "outputs": [],
      "source": [
        "# Define our input data and learning rate\n",
        "xs = [-1.0, 0.0, 1.0, 2.0, 3.0, 4.0]\n",
        "ys = [-3.0, -1.0, 1.0, 3.0, 5.0, 7.0]\n",
        "LEARNING_RATE=0.09\n",
        "\n",
        "# Instantiate our model\n",
        "model = Model()\n",
        "\n",
        "# Collect the history of w-values and b-values to plot later\n",
        "list_w, list_b = [], []\n",
        "epochs = range(50)\n",
        "losses = []\n",
        "for epoch in epochs:\n",
        "  list_w.append(model.w.numpy())\n",
        "  list_b.append(model.b.numpy())\n",
        "  current_loss = train(model, xs, ys, learning_rate=LEARNING_RATE)\n",
        "  losses.append(current_loss)\n",
        "  print(f\"Epoch {epoch:2d}: w={list_w[-1]:1.2f} b={list_b[-1]:1.2f}, \"\n",
        "        f\"loss={current_loss:2.5f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kx_xreFVtBco"
      },
      "source": [
        "### Plot our trained values over time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGgb5grSk8Ax",
        "outputId": "c52b332d-3965-47da-956a-9ed2a9f17d2a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-14749d498bef>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mTRUE_w\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mTRUE_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_w\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRUE_w\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r--'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTRUE_b\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b--'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'True w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'True b'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ],
      "source": [
        "# Plot the w-values and b-values for each training Epoch against the true values\n",
        "TRUE_w = 2.0\n",
        "TRUE_b = -1.0\n",
        "plt.plot(epochs, list_w, 'r', epochs, list_b, 'b')\n",
        "plt.plot([TRUE_w] * len(epochs), 'r--', [TRUE_b] * len(epochs), 'b--')\n",
        "plt.legend(['w', 'b', 'True w', 'True b'])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Mimimizing-Loss.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}